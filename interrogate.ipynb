{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features metadata (True/False values across 17 tags):\n",
      "      feature  tag_0  tag_1  tag_2  tag_3  tag_4  tag_5  tag_6  tag_7  tag_8  \\\n",
      "0  feature_00  False  False   True  False  False  False  False  False  False   \n",
      "1  feature_01  False  False   True  False  False  False  False  False  False   \n",
      "2  feature_02  False  False   True  False  False  False  False  False  False   \n",
      "3  feature_03  False  False   True  False  False  False  False  False  False   \n",
      "4  feature_04  False  False   True  False  False  False  False  False  False   \n",
      "\n",
      "   tag_9  tag_10  tag_11  tag_12  tag_13  tag_14  tag_15  tag_16  \n",
      "0  False   False   False   False   False    True   False    True  \n",
      "1  False   False   False   False    True    True   False    True  \n",
      "2  False   False   False    True   False   False   False    True  \n",
      "3  False   False   False   False    True   False   False    True  \n",
      "4  False   False   False    True    True   False   False    True  \n",
      "\n",
      "Responders metadata (True/False values across 5 tags):\n",
      "     responder  tag_0  tag_1  tag_2  tag_3  tag_4\n",
      "0  responder_0   True  False   True  False  False\n",
      "1  responder_1   True  False  False   True  False\n",
      "2  responder_2   True   True  False  False  False\n",
      "3  responder_3  False  False   True  False   True\n",
      "4  responder_4  False  False  False   True   True\n",
      "\n",
      "Distribution of True/False values per feature:\n",
      "- 17 features have 1 True and 16 False\n",
      "- 24 features have 2 True and 15 False\n",
      "- 30 features have 3 True and 14 False\n",
      "- 8 features have 4 True and 13 False\n",
      "\n",
      "Each feature has 17 tags total\n",
      "Min True values in a feature: 1 (with 16 False)\n",
      "Max True values in a feature: 4 (with 13 False)\n",
      "Mean True values per feature: 2.37\n",
      "\n",
      "First 10 features and their True/False counts:\n",
      "      feature  True_count  False_count\n",
      "0  feature_00           3           14\n",
      "1  feature_01           4           13\n",
      "2  feature_02           3           14\n",
      "3  feature_03           3           14\n",
      "4  feature_04           4           13\n",
      "5  feature_05           3           14\n",
      "6  feature_06           3           14\n",
      "7  feature_07           3           14\n",
      "8  feature_08           2           15\n",
      "9  feature_09           1           16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Look at features metadata\n",
    "features_df = pd.read_csv('features.csv')\n",
    "num_feature_tags = sum(1 for col in features_df.columns if col.startswith('tag_'))\n",
    "print(f\"Features metadata (True/False values across {num_feature_tags} tags):\")\n",
    "print(features_df.head())\n",
    "\n",
    "# Look at responders metadata\n",
    "responders_df = pd.read_csv('responders.csv')\n",
    "num_responder_tags = sum(1 for col in responders_df.columns if col.startswith('tag_'))\n",
    "print(f\"\\nResponders metadata (True/False values across {num_responder_tags} tags):\")\n",
    "print(responders_df.head())\n",
    "\n",
    "# Count number of True values for each feature\n",
    "tag_counts_per_feature = features_df.iloc[:, 1:].sum(axis=1)  # Skip 'feature' column\n",
    "\n",
    "# Create summary\n",
    "print(\"\\nDistribution of True/False values per feature:\")\n",
    "value_counts = tag_counts_per_feature.value_counts().sort_index()\n",
    "for true_count, num_features in value_counts.items():\n",
    "    print(f\"- {num_features} features have {true_count} True and {num_feature_tags-true_count} False\")\n",
    "\n",
    "print(f\"\\nEach feature has {num_feature_tags} tags total\")\n",
    "print(f\"Min True values in a feature: {tag_counts_per_feature.min()} (with {num_feature_tags-tag_counts_per_feature.min()} False)\")\n",
    "print(f\"Max True values in a feature: {tag_counts_per_feature.max()} (with {num_feature_tags-tag_counts_per_feature.max()} False)\")\n",
    "print(f\"Mean True values per feature: {tag_counts_per_feature.mean():.2f}\")\n",
    "\n",
    "# Show first few features with their True/False counts\n",
    "results = pd.DataFrame({\n",
    "    'feature': features_df['feature'],\n",
    "    'True_count': tag_counts_per_feature,\n",
    "    'False_count': num_feature_tags - tag_counts_per_feature\n",
    "})\n",
    "print(\"\\nFirst 10 features and their True/False counts:\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_metadata():\n",
    "    # Read metadata\n",
    "    features_df = pd.read_csv('features.csv')\n",
    "    responders_df = pd.read_csv('responders.csv')\n",
    "    \n",
    "    # Analyze feature tags\n",
    "    feature_tag_counts = features_df.iloc[:, 1:].sum()  # Skip 'feature' column\n",
    "    print(\"Feature tag counts:\")\n",
    "    print(feature_tag_counts)\n",
    "    print(f\"\\nTotal features: {len(features_df)}\")\n",
    "    \n",
    "    # Analyze responder tags\n",
    "    responder_tag_counts = responders_df.iloc[:, 1:].sum()  # Skip 'responder' column\n",
    "    print(\"\\nResponder tag counts:\")\n",
    "    print(responder_tag_counts)\n",
    "    print(f\"\\nTotal responders: {len(responders_df)}\")\n",
    "    \n",
    "    # See which features share same tag patterns\n",
    "    feature_patterns = features_df.iloc[:, 1:].apply(tuple, axis=1)\n",
    "    pattern_counts = feature_patterns.value_counts()\n",
    "    print(\"\\nCommon feature tag patterns:\")\n",
    "    print(pattern_counts.head())\n",
    "    \n",
    "    return features_df, responders_df\n",
    "\n",
    "# Run analysis\n",
    "features_df, responders_df = analyze_metadata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
