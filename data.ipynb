{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "features_df = pd.read_csv('features.csv')\n",
    "\n",
    "# Look at first few features that show NaN in your time series\n",
    "nan_features = ['feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_73', 'feature_74']\n",
    "\n",
    "# Extract tag patterns for these features\n",
    "nan_patterns = features_df[features_df['feature'].isin(nan_features)]\n",
    "print(\"Tag patterns for features that show NaN values:\")\n",
    "print(nan_patterns)\n",
    "\n",
    "# Count True values for each tag column in NaN features\n",
    "print(\"\\nCount of True values for each tag in NaN features:\")\n",
    "true_counts = nan_patterns.iloc[:, 1:].sum()\n",
    "print(true_counts[true_counts > 0])  # Only show tags that are True for any of these features\n",
    "\n",
    "# Also look at some features that don't have NaN\n",
    "non_nan_features = ['feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09']\n",
    "non_nan_patterns = features_df[features_df['feature'].isin(non_nan_features)]\n",
    "print(\"\\nTag patterns for features that don't show NaN values:\")\n",
    "print(non_nan_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from methods import prepare_regression_data, train_model, evaluate_model, plot_separate_timeseries, create_timeseries_for_symbol\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_parquet(\"train.parquet/partition_id=0/part-0.parquet\")\n",
    "    symbol_id = df['symbol_id'].unique()[0]\n",
    "    \n",
    "    # Create time series\n",
    "    features, responders, target = create_timeseries_for_symbol(df, symbol_id)\n",
    "    \n",
    "    # Plot\n",
    "    plot_separate_timeseries(features, responders, target)\n",
    "\n",
    "    # Prepare regression data\n",
    "    X, y = prepare_regression_data(features, responders, target)\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    model, X_train, X_test, y_train, y_test = train_model(X, y)\n",
    "    evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import train_xgboost_model\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_parquet(\"train.parquet/partition_id=0/part-0.parquet\")\n",
    "    symbol_id = df['symbol_id'].unique()[0]\n",
    "    \n",
    "    # Create time series\n",
    "    features, responders, target = create_timeseries_for_symbol(df, symbol_id)\n",
    "    \n",
    "    # Prepare regression data\n",
    "    X, y = prepare_regression_data(features, responders, target)\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    model, X_train, X_test, y_train, y_test = train_xgboost_model(X, y)\n",
    "    evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Print feature importances\n",
    "    feature_importance = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 most important features:\")\n",
    "    print(feature_importance.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
